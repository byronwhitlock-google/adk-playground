import random
import time
from google.adk.agents import Agent
from google.adk.tools import ToolContext
from google.adk.tools.agent_tool import AgentTool
from google.cloud import aiplatform

from google import genai
from google.genai import types

from vertexai.preview.generative_models import GenerativeModel
import vertexai

from typing import Sequence, Dict, Any

#  Load the instructions from the immersive.  In a real application, you might
#  load this from a file or a database.  Here, we're including it directly
#  for clarity and completeness.
producer_agent_instructions = """
# Instructions for the Producer Agent
description: >
  You are an expert Commercial Producer AI Agent. Your primary function is to
  translate unstructured user thoughts and ideas for a commercial into a
  structured technical blueprint for production. You will analyze the user's
  creative brief and generate a detailed breakdown including scenes, 
  music theme notes, and text overlay requirements. 

    Each scene will be exactly 8 seconds long, no more than 2 scenes total.
    
    You will also call the video generation tool to create the visual content
    for each scene. Allow person generation.

    After video generation is complete, you call the video joining tool to merge videos together.

    You will return a joined video to the user.
  """

async def video_generation_tool(
    prompt: str,
    generateVideoConfig: types.GenerateVideosConfig 
):
    """Tool to generate an 8 second video clip from an description using Veo2.
    
    Args:
        prompt (str): The prompt to be sent to the video generation tool
        generateVideoConfig (types.GenerateVideosConfig): The configuration for the video generation tool.
    Returns:
        types.GenerateVideosResponse: The response from the video generation tool. 

    """
    try:
        # Initialize the client for the Generative AI API
        client = genai.Client()

        # Create an operation to generate a video
        operation = client.models.generate_videos (
            model="veo-2.0-generate-001",
            prompt=prompt,
            config=generateVideoConfig,
            # config=types.GenerateVideosConfig(
            #     person_generation="dont_allow",  # Safety setting
            #     aspect_ratio="16:9",  # Landscape format
            # ),
        )

        # Wait for video generation to complete
        while not operation.done:
            time.sleep(20)
            operation = client.operations.get(operation)

        return operation.response.generated_videos
        
    except Exception as e:
        return f"Error generating video: {str(e)}"
        # For development/testing, return a mock URL if the API call fails
        # r = random.random()
        # return f"https://example.com/video{r}.mp4"
   


async def depercated_call_video_generation_agent(
    question: str
):
    """Tool to call video generation agent (video_generation_agent) agent.
    
    Args:
        question (str): The question or prompt to be sent to the video generation agent.
    Returns:
        str: url to the generated video.
    """
    
    agent_tool = AgentTool(agent=video_generation_agent)
    tool_context = agent_tool.create_tool_context()
    #  Set the state for the tool context.  This is where you can pass
    #  any additional information or context needed for the agent.
    tool_context.state["question"] = question
    #  Run the agent tool asynchronously.  This will call the video generation
    #  agent with the provided question and context.
    #  The agent will process the question and return the generated video
    #  generation prompts.
    #  The output will be stored in the tool context state.
    #  You can access the output later in the workflow.        

    video_generation_output = await agent_tool.run_async(
        args={"request": question}, tool_context=tool_context
    )
    tool_context.state["video_generation_output"] = video_generation_output
    return video_generation_output


# Initialize the LLM agent with the specified instructions.  We're using
# Gemini 2.5 Pro.  You might need to adjust the model name depending on
# your available models and GCP project setup.
root_agent = Agent(
    name="video_producer_agent",
    model="gemini-2.0-flash",  #  Make sure this is the correct model identifier
    instruction=producer_agent_instructions,
    tools=[video_generation_tool],  #  Add the video generation agent as a tool
    
)


# Test prompt: I want a commercial for Google PSO. I want to highlight specifically Byron Whitlock. He is a top engineer. Add text about how he is a "1337 h4x0rz". He will 100x your ROI. Every cloud project will come in on time and under budget when he is on the team. Every time you choose Byron, a  butterfly gains her wings. <insert appropriate chuck norris homily> He is a cloud engineer a software engineer and a wrangler of cats, specifically maine coons. Go over the top on superlatives and make the commercial light and funny. End it with "contact your TAM for pricing". 
